{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#Dataset hyperparameters\n",
    "NUM_TRAIN = 49000\n",
    "batch_size = 64\n",
    "\n",
    "#Normalize CIFAR-10 images using RGB channels' known means and stdvs\n",
    "CIFAR10_transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "#Download and normalize train, val, test datasets\n",
    "cifar10_train = dset.CIFAR10('./datasets', train=True, download=True, transform=CIFAR10_transform)\n",
    "cifar10_val = dset.CIFAR10('./datasets', train=True, download=True, transform=CIFAR10_transform)\n",
    "cifar10_test = dset.CIFAR10('./datasets', train=False, download=True, transform=CIFAR10_transform)\n",
    "\n",
    "#Split train,val set, load datasets into usable form.\n",
    "loader_train = DataLoader(cifar10_train, batch_size=batch_size,\n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "loader_val = DataLoader(cifar10_val, batch_size=batch_size,\n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN,50000)))\n",
    "loader_test = DataLoader(cifar10_test, batch_size=batch_size)\n",
    "\n",
    "#indicate whether or not to use a GPU\n",
    "USE_GPU = False\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "#set tensor datatypes\n",
    "dtype = torch.float32\n",
    "\n",
    "#how often to print training loss\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten function for Conv --> FC layer connections\n",
    "def flatten(x):\n",
    "    N = x.shape[0]\n",
    "    return x.view(N, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic ConvNet (module API)\n",
    "class BasicNet(nn.Module):\n",
    "    def __init__(self, in_channel, channel_1, channel_2, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channel,channel_1,3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(channel_1,channel_2,3,padding=1)\n",
    "        self.fc1 = nn.Linear(channel_2*32*32,num_classes)\n",
    "    \n",
    "    def forward(self,x):    \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = flatten(x)       \n",
    "        scores = self.fc1(x)\n",
    "        \n",
    "        return scores        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "#make sure our net is wired correctly, should output [64,10] tensor\n",
    "def testBasicNet():\n",
    "    x = torch.zeros((64,3,32,32),dtype=dtype)\n",
    "    model = BasicNet(3,16,16,10)\n",
    "    scores = model(x)\n",
    "    print(scores.size())\n",
    "    \n",
    "testBasicNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check accuracy of model predictions. For use in training loop.\n",
    "def checkAccuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print(\"Checking accuracy on validation set\")\n",
    "    else:\n",
    "        print(\"Checking accuracy\")\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() #set model to eval mode\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to GPU if in use\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _,preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        accuracy = float(num_correct)/num_samples\n",
    "        print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "def train(model, optimizer, epochs=1):\n",
    "    model = model.to(device=device)  # move the model parameters to GPU if in use\n",
    "    for e in range(epochs):\n",
    "        print(\"Epoch %d\" % (e))\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train() #set model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to GPU if in use\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            #get model predictions and compute loss (cross-entropy)\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores,y)\n",
    "\n",
    "            #zero all gradients that optimizer updates (running gradients will be applied if we do not do this)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            #update model parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # print results every print_every iterations\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                checkAccuracy(loader_val, model)\n",
    "                print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Iteration 0, loss = 2.2867\n",
      "Checking accuracy on validation set\n",
      "Got 80 / 1000 correct (8.00%)\n",
      "\n",
      "Iteration 100, loss = 1.6309\n",
      "Checking accuracy on validation set\n",
      "Got 436 / 1000 correct (43.60%)\n",
      "\n",
      "Iteration 200, loss = 1.3448\n",
      "Checking accuracy on validation set\n",
      "Got 484 / 1000 correct (48.40%)\n",
      "\n",
      "Iteration 300, loss = 1.4642\n",
      "Checking accuracy on validation set\n",
      "Got 515 / 1000 correct (51.50%)\n",
      "\n",
      "Iteration 400, loss = 1.2168\n",
      "Checking accuracy on validation set\n",
      "Got 555 / 1000 correct (55.50%)\n",
      "\n",
      "Iteration 500, loss = 1.1370\n",
      "Checking accuracy on validation set\n",
      "Got 565 / 1000 correct (56.50%)\n",
      "\n",
      "Iteration 600, loss = 1.0400\n",
      "Checking accuracy on validation set\n",
      "Got 586 / 1000 correct (58.60%)\n",
      "\n",
      "Iteration 700, loss = 1.1179\n",
      "Checking accuracy on validation set\n",
      "Got 606 / 1000 correct (60.60%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test model\n",
    "learning_rate = 3e-4\n",
    "in_channel = 3\n",
    "channel_1 = 32\n",
    "channel_2 = 64\n",
    "num_classes = 10\n",
    "\n",
    "model = BasicNet(in_channel,channel_1,channel_2,num_classes)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train(model,optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
